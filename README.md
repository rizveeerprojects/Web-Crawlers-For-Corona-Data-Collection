# Web-Crawlers-For-Corona-Data-Collection
This repository is developed for the collection of corona related data from newspaper, web pages, important articles through diffrent types of crawlers. Main goal is to collect and visualize COVID-19 related information appeared in different sources. Currently we include the crawleres for the following papers. 

* The Guardian 
* The New York Times 
* The Prothom Alo 

## Getting Started
These instructions will get you a copy of the project up and running on your local machine.


### Prerequisites
The requirements to run this project are given following - 
```
Java Version 14
```
```
Python Version 3.x; x>=6
```

### Installation
Create a directory and go there. Open your terminal and type the following command. If you are not comfortable with using terminal, please download this repository as zip from the above option and unzip it within the created directory.

```
git clone https://github.com/rizveeerprojects/Web-Crawlers-For-Corona-Data-Collection.git
```

## Running the Crawlers 

* Go to your desired newspaper folder(Guardian, New-York-Times etc.) 
* Within your folder, you will get a script file. Run it. Newspaper crawling will start. All sorts of news related to coronavirus will be saved into respective csv file. 


